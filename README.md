# RECOMMENDARE

The 4th industrial revolution is powered by the latest research in Artificial Intelligence (AI), Computer Vision and Machine Learning (ML). Increasing amount of businesses employ ML to help them analyse current trends and predict future trends or to help their customers with provided services. Unfortunately, due to the complexity of most machine learning approaches, it is not possible to access or understand why a machine took a given decision based on its inputs (i.e. black box approach). Without a clear understanding, it is hard to incorporate user knowledge and achieve a better learning performance. Moreover, when users are not able to verify and challenge the decision process, it reduces trust and compliance of such system, limiting the application in critical fields, such as medicine, law or public service. For example, in medicine, the disease identification and diagnosis of ailments are at the forefront of machine learning research, yet even with current efforts the challenge of how to interpret the decisions taken by ML systems

remains. As a result, academics, as well as mass media, often report that doctors can now operate with high precision prediction systems for automated diagnosis, but only rarely they choose to fully trust them. The key challenge is to design a visual explanation mechanism tightly integrated into a machine learning model, yet applicable to various machine learning techniques in different domains. Such a mechanism will allow interpretation of complex intermediary data (i.e. evidence) created and processed by an ML system and let users understand system decisions based on the presented evidence. Users should be able to manipulate evidence using interactive visualisations to participate in the ML process.

The problem of using standard methods of visualisation in 2D spaces (e.g. plots, histograms) arises in scenarios with complex relationships, soon becoming cluttered and confusing. With current advances in Virrtual Reality and Augmented Reality, we seek to employ 3D environments, allowing users to operate the content in three dimensions, obtaining the extra space for complex visualisations.

The objective of this project is to deliver a recommended systems framework endowed with an explanation mechanism of recommendations. To achieve goals of this project, we separate the efforts into Master project 1 and 2. In Master project 1, student will perform a deep analysis of recommender system frameworks, methods and algorithms, delivering an augmented ML algorithm used in recommender systems for digital content (Hu et al., 2012) and (Sun et al., 2015). In Master project 2: student will implement the augmented recommender system framework that allows the direct manipulation of intermediary data to deliver different recommendations. The initial intent is to deliver a 3D (VR-based) systems.

We believe that outcomes of this project will have significant impact on target domains. Our frameworks will allow to develop or augment existing complex decision making and monitoring systems.

[Next](Logbook/week1.md)
